{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 32.00 GB\n",
      "maxCacheSize: 10.67 GB\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:52:30.811249: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-29 14:52:30.811382: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from src.preprocess.VoiceBankDEMAND import VoiceBandDEMAND\n",
    "from src.preprocess.feature_extractor import FeatureExtractor\n",
    "from src.utils import read_audio, load_yaml\n",
    "from src.distrib import load_model\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "# %load_ext tensorboard\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# SHOULD PUT model path\n",
    "model_path = Path(f'./history/221122-1127/data/20221123-183326')\n",
    "path_conf = os.path.join(model_path, \"config.yaml\")\n",
    "args = load_yaml(path_conf)\n",
    "args.model.path = model_path.as_posix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:52:31.900350: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-29 14:52:31.900373: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Paramter\n",
    "device_lib.list_local_devices()\n",
    "tf.random.set_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "\n",
    "model_name = args.model.name\n",
    "save_path = args.dset.save_path\n",
    "flag_fft = args.dset.fft\n",
    "nfft = args.dset.n_fft\n",
    "hop_length = args.dset.hop_length\n",
    "center = args.dset.center\n",
    "num_features = args.model.n_feature\n",
    "num_segments = args.model.n_segment\n",
    "normalization = args.dset.normalize\n",
    "fft_normalization = args.dset.fft_normalize\n",
    "top_db = args.dset.top_db\n",
    "train_split = int(args.dset.split*100)\n",
    "sample_rate = args.dset.sample_rate\n",
    "win_length = args.dset.win_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:52:31.976699: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-11-29 14:52:31.976728: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input (InputLayer)             [(None, 2, 1, 64, 2  0           []                               \n",
      "                                57)]                                                              \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (Slic  (None, 1, 64, 257)  0           ['input[0][0]']                  \n",
      " ingOpLambda)                                                                                     \n",
      "                                                                                                  \n",
      " tf.compat.v1.squeeze (TFOpLamb  (None, 64, 257)     0           ['tf.__operators__.getitem[0][0]'\n",
      " da)                                                             ]                                \n",
      "                                                                                                  \n",
      " mel_spec (MelSpec)             (None, 64, 128)      0           ['tf.compat.v1.squeeze[0][0]']   \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64, 256)      394240      ['mel_spec[0][0]']               \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 64, 256)      525312      ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 256)     1024        ['lstm_1[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64, 128)      32896       ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 64, 128)      16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " inverse_mel_spec (InverseMelSp  (None, 64, 257)     0           ['dense_1[0][0]']                \n",
      " ec)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 1, 64, 257)   0           ['inverse_mel_spec[0][0]']       \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 1, 64, 257)   0           ['tf.__operators__.getitem[0][0]'\n",
      "                                                                 , 'tf.expand_dims[0][0]']        \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1 (Sl  (None, 1, 64, 257)  0           ['input[0][0]']                  \n",
      " icingOpLambda)                                                                                   \n",
      "                                                                                                  \n",
      " tf.stack (TFOpLambda)          (None, 2, 1, 64, 25  0           ['multiply[0][0]',               \n",
      "                                7)                                'tf.__operators__.getitem_1[0][0\n",
      "                                                                 ]']                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 969,984\n",
      "Trainable params: 969,472\n",
      "Non-trainable params: 512\n",
      "__________________________________________________________________________________________________\n",
      "Loading Model...\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "WARNING:tensorflow:Unable to restore custom metric. Please ensure that the layer implements `get_config` and `from_config` when saving. In addition, please use the `custom_objects` arg when calling `load_model()`.\n",
      "Optimizer Loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:52:35.346190: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-11-29 14:52:36.177122: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-29 14:52:36.513393: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-29 14:52:36.677800: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-29 14:52:36.999339: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-29 14:52:37.322978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 0.5156\n",
      "Optimizer was loaded!\n"
     ]
    }
   ],
   "source": [
    "# 3. Build and Load Model\n",
    "model = load_model(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File example:\n",
      "Clean:  /Users/seunghyunoh/workplace/research/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791/clean_testset_wav/p232_001.wav The number:  824\n",
      "Noisy:  /Users/seunghyunoh/workplace/research/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791/noisy_testset_wav/p232_001.wav The number:  824\n",
      "# of Noise testing files: 824\n",
      "Clean:  /Users/seunghyunoh/workplace/research/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791/clean_testset_wav/p232_005.wav\n",
      "Noisy:  /Users/seunghyunoh/workplace/research/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791/noisy_testset_wav/p232_005.wav\n",
      "Min: 1.3051452280032905e-11 Max: 0.6614166143827909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #271: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load audio file\n",
    "\n",
    "dataset_path = \"/Users/seunghyunoh/workplace/research/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791\"\n",
    "dataset_voicebank = VoiceBandDEMAND(dataset_path, val_dataset_percent=0.3)\n",
    "clean_test_filenames, noisy_test_filenames = dataset_voicebank.get_test_filenames()\n",
    "clean_file = clean_test_filenames[3] \n",
    "noisy_file = noisy_test_filenames[3]\n",
    "\n",
    "clean_file = \"/Users/seunghyunoh/workplace/research/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791/clean_testset_wav/p232_005.wav\"\n",
    "noisy_file = \"/Users/seunghyunoh/workplace/research/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791/noisy_testset_wav/p232_005.wav\"\n",
    "\n",
    "# clean_file = \"/home/daniel0413/workplace/project/SpeechEnhancement/example/sample_compare/441c020r/clean.wav\"\n",
    "# noisy_file = \"/home/daniel0413/workplace/project/SpeechEnhancement/example/sample_compare/441c020r/dirty.wav\"\n",
    "\n",
    "print(\"Clean: \", clean_file)\n",
    "print(\"Noisy: \", noisy_file)\n",
    "\n",
    "clean_audio, sr = read_audio(clean_file, sample_rate)\n",
    "noisy_audio, sr = read_audio(noisy_file, sample_rate)\n",
    "\n",
    "mean_noisy = np.mean(noisy_audio)\n",
    "std_noisy = np.std(noisy_audio)\n",
    "noisy_audio_norm = (noisy_audio - mean_noisy) / std_noisy\n",
    "\n",
    "noisy_audio_feature_extractor = FeatureExtractor(noisy_audio_norm, windowLength=win_length, hop_length=hop_length, sample_rate=sr)\n",
    "noisy_stft_features = noisy_audio_feature_extractor.get_stft_spectrogram(center)\n",
    "\n",
    "noisy_stft_features /= nfft\n",
    "\n",
    "# Paper: Besides, spectral phase was not used in the training phase.\n",
    "# At reconstruction, noisy spectral phase was used instead to\n",
    "# perform in- verse STFT and recover human speech.\n",
    "\n",
    "noisy_phase = np.angle(noisy_stft_features)\n",
    "noisy_amplitude = np.abs(noisy_stft_features)\n",
    "\n",
    "\n",
    "# For metrics\n",
    "mean_clean = np.mean(clean_audio)\n",
    "std_clean = np.std(clean_audio)\n",
    "clean_audio_norm = (clean_audio - mean_clean) / std_clean\n",
    "clean_audio_feature_extractor = FeatureExtractor(clean_audio_norm, windowLength=win_length, hop_length=hop_length, sample_rate=sr)\n",
    "clean_stft_features = clean_audio_feature_extractor.get_stft_spectrogram(center)\n",
    "clean_stft_features /= nfft\n",
    "clean_phase = np.angle(clean_stft_features)\n",
    "clean_amplitude = np.abs(clean_stft_features)\n",
    "\n",
    "print(\"Min:\", np.min(clean_amplitude),\"Max:\",np.max(clean_amplitude))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:52:38.507577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-11-29 14:52:38.661379: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/13 [=>............................] - ETA: 8s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-29 14:52:38.832533: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 50ms/step\n",
      "Min: -0.5340567 Max: 0.42722604\n"
     ]
    }
   ],
   "source": [
    "def _prepare_input_features(stft_features, numSegments, numFeatures):\n",
    "    stftSegments = np.zeros((numFeatures, numSegments, stft_features.shape[1]))\n",
    "    for index in range(stft_features.shape[1]-numSegments+1):\n",
    "        stftSegments[..., index] = stft_features[..., index:index + numSegments]\n",
    "    return stftSegments\n",
    "\n",
    "def _prepare_input_features_zero_filled(stft_features, numSegments, numFeatures):\n",
    "    noisySTFT = np.concatenate([np.zeros_like(stft_features[:, 0:numSegments - 1]), stft_features], axis=1)\n",
    "    stftSegments = np.zeros((numFeatures, numSegments, noisySTFT.shape[1] - numSegments + 1))\n",
    "    for index in range(noisySTFT.shape[1] - numSegments + 1):\n",
    "        stftSegments[..., index] = noisySTFT[..., index:index + numSegments]\n",
    "    return stftSegments\n",
    "\n",
    "\n",
    "def revert_features_to_audio(features, phase, mean=None, std=None):\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    # features = librosa.db_to_power(features)\n",
    "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
    "\n",
    "    features = np.transpose(features, (1, 0))\n",
    "    features *= nfft\n",
    "    estimated_audio = noisy_audio_feature_extractor.get_audio_from_stft_spectrogram(features, center)\n",
    "    \n",
    "    # scale the outpus back to the original range\n",
    "    if mean and std:\n",
    "        estimated_audio = std * estimated_audio + mean\n",
    "    \n",
    "    return estimated_audio\n",
    "\n",
    "\n",
    "noisy_ampltidue_input = _prepare_input_features_zero_filled(noisy_amplitude, num_segments, num_features)\n",
    "noisy_ampltidue_input = np.transpose(noisy_ampltidue_input, (2, 1, 0)).astype(np.float32)\n",
    "\n",
    "noisy_phase_input = _prepare_input_features_zero_filled(noisy_phase, num_segments, num_features)\n",
    "noisy_phase_input = np.transpose(noisy_phase_input, (2, 1, 0)).astype(np.float32)\n",
    "\n",
    "noisy_input = np.stack([noisy_ampltidue_input, noisy_phase_input], axis=1)\n",
    "noisy_input = np.expand_dims(noisy_input, axis=2)\n",
    "estimation_amp_phase = model.predict(noisy_input)\n",
    "\n",
    "estimation_amp_phase = estimation_amp_phase[..., -1, :]\n",
    "estimation_amp_phase = np.squeeze(estimation_amp_phase)\n",
    "\n",
    "if model_name == 'lstm':\n",
    "    estimation = revert_features_to_audio(estimation_amp_phase[:, 0, :], estimation_amp_phase[:, 1, :], mean_noisy, std_noisy)\n",
    "\n",
    "print(\"Min:\", np.min(estimation),\"Max:\",np.max(estimation))\n",
    "# ipd.Audio(data=estimation, rate=fs) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.070292353630066 ----> 2.924632728099823\n",
      "0.9577148407697678 ----> 5.680829882621765\n",
      "-0.144052030518651 ----> 7.788050174713135\n",
      "3.0900216102600098 ----> 5.8359068632125854\n",
      "11.649209260940552 ----> 7.882385849952698\n",
      "5.249779224395752 ----> 6.3077312707901\n",
      "5.746272802352905 ----> 6.354302763938904\n"
     ]
    }
   ],
   "source": [
    "\n",
    "noisy_bypass = noisy_input[..., -1, :]\n",
    "noisy_bypass = np.squeeze(noisy_bypass)\n",
    "noisy_bypass = revert_features_to_audio(noisy_bypass[:, 0, :], noisy_bypass[:, 1, :], mean_noisy, std_noisy)\n",
    "\n",
    "clean_ampltidue_input = _prepare_input_features_zero_filled(clean_amplitude, num_segments, num_features)\n",
    "clean_ampltidue_input = np.transpose(clean_ampltidue_input, (2, 1, 0)).astype(np.float32)\n",
    "\n",
    "clean_phase_input = _prepare_input_features_zero_filled(clean_phase, num_segments, num_features)\n",
    "clean_phase_input = np.transpose(clean_phase_input, (2, 1, 0)).astype(np.float32)\n",
    "\n",
    "clean_input = np.stack([clean_ampltidue_input, clean_phase_input], axis=1)\n",
    "clean_input = np.expand_dims(clean_input, axis=2)\n",
    "\n",
    "clean_bypass = clean_input[..., -1, :]\n",
    "clean_bypass = np.squeeze(clean_bypass)\n",
    "clean_bypass = revert_features_to_audio(clean_bypass[:, 0, :], clean_bypass[:, 1, :], mean_clean, std_clean)\n",
    "\n",
    "from src.metrics import SI_SDR\n",
    "\n",
    "metric = SI_SDR\n",
    "\n",
    "estimation_metric = estimation\n",
    "\n",
    "new_shape = list(clean_bypass.shape)\n",
    "nsegment_metric = int(new_shape[-1]//sample_rate)\n",
    "new_shape += [0]\n",
    "new_shape[-2:] = nsegment_metric, sample_rate\n",
    "\n",
    "clean_bypass = clean_bypass[:nsegment_metric*sample_rate]\n",
    "clean_bypass = np.reshape(clean_bypass, new_shape)\n",
    "noisy_bypass = noisy_bypass[:nsegment_metric*sample_rate]\n",
    "noisy_bypass = np.reshape(noisy_bypass, new_shape)\n",
    "estimation_metric = estimation[:nsegment_metric*sample_rate]\n",
    "estimation_metric = np.reshape(estimation_metric, new_shape)\n",
    "\n",
    "for clean_seg, noisy_seg, est_seg in zip(clean_bypass, noisy_bypass, estimation_metric):\n",
    "    SISDR_prev = metric(clean_seg, noisy_seg, sample_rate)\n",
    "    SISDR_after = metric(clean_seg, est_seg, sample_rate)\n",
    "    print(SISDR_prev, \"---->\", SISDR_after)\n",
    "\n",
    "SISDR_prev = metric(clean_bypass, noisy_bypass, sample_rate)\n",
    "SISDR_after = metric(clean_bypass, estimation_metric, sample_rate)\n",
    "print(SISDR_prev, \"---->\", SISDR_after)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True)\n",
    "\n",
    "ax1.plot(clean_audio)\n",
    "ax1.set_title(\"Clean Audio\")\n",
    "\n",
    "ax2.plot(noisy_audio)\n",
    "ax2.set_title(\"Noisy Audio\")\n",
    "\n",
    "ax3.plot(estimation)\n",
    "ax3.set_title(\"Denoised Audio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=clean_audio, rate=sample_rate) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=noisy_audio, rate=sample_rate) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=estimation, rate=sample_rate) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1, ax2) = plt.subplots(3, 1, sharey=True)\n",
    "\n",
    "def show_stft(y, _fig, _ax):\n",
    "    D = librosa.stft(y)  # STFT of y\n",
    "    S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)\n",
    "    img = librosa.display.specshow(S_db, ax=_ax)\n",
    "    _fig.colorbar(img, ax=_ax)\n",
    "\n",
    "show_stft(estimation, fig, ax0)\n",
    "show_stft(clean_audio, fig, ax1)\n",
    "show_stft(noisy_audio, fig, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bose_file = \"/home/daniel0413/workplace/project/SpeechEnhancement/example/sample_compare/441c020r/proc.wav\"\n",
    "# boseAudio, sr = read_audio(bose_file, sample_rate)\n",
    "# ipd.Audio(data=boseAudio, rate=sample_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7c2bc294fb4a4c68eb1f6998c466cc1127bf5e3b69a7adb6cd789b68ede878a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
