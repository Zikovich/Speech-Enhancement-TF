{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode\n",
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from data_processing.VoiceBankDEMAND import VoiceBandDEMAND\n",
    "from data_processing.feature_extractor import FeatureExtractor\n",
    "from utils import prepare_input_features, read_audio\n",
    "from model import build_model, build_model_lstm\n",
    "# Load the TensorBoard notebook extension.\n",
    "# %load_ext tensorboard\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras.models\n",
    "\n",
    "device_lib.list_local_devices()\n",
    "\n",
    "tf.random.set_seed(999)\n",
    "np.random.seed(999)\n",
    "\n",
    "# model_name = 'cnn'\n",
    "model_name = 'lstm'\n",
    "\n",
    "path_to_dataset = f\"./records_{model_name}\"\n",
    "\n",
    "\n",
    "if model_name == \"cnn\":\n",
    "  windowLength = 256\n",
    "  overlap      = round(0.25 * windowLength) # overlap of 75%\n",
    "  ffTLength    = windowLength\n",
    "  inputFs      = 48e3\n",
    "  fs           = 16e3\n",
    "  numFeatures  = ffTLength//2 + 1\n",
    "  numSegments  = 8\n",
    "  model = build_model(l2_strength=0.0)\n",
    "\n",
    "if model_name == \"lstm\":\n",
    "  windowLength = 512\n",
    "  overlap      = round(0.5 * windowLength) # overlap of 75%\n",
    "  ffTLength    = windowLength\n",
    "  inputFs      = 48e3\n",
    "  fs           = 16e3\n",
    "  numFeatures  = ffTLength//2 + 1\n",
    "  numSegments  = 63 # 1 sec in 512 window, 256 hop, sr = 16000 Hz\n",
    "  model = build_model_lstm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model_path = Path(f'./result/{model_name}/20220927-120628/')\n",
    "\n",
    "# Model load\n",
    "model = keras.models.load_model(model_path / \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voiceBankDEMAND_basepath = '/Users/seunghyunoh/workplace/study/NoiseReduction/Tiny-SpeechEnhancement/data/VoiceBankDEMAND/DS_10283_2791'\n",
    "voiceBankDEMAND_basepath = '/home/daniel0413/workplace/project/SpeechEnhancement/TinyML/data/VoiceBankDEMAND'\n",
    "\n",
    "voiceBank = VoiceBandDEMAND(voiceBankDEMAND_basepath, val_dataset_percent=0.3)\n",
    "clean_test_filenames, noisy_test_filenames = voiceBank.get_test_filenames()\n",
    "\n",
    "clean_file = clean_test_filenames[5] # select file\n",
    "noisy_file = noisy_test_filenames[5]\n",
    "\n",
    "print(\"Clean: \", clean_file)\n",
    "print(\"Noisy: \", noisy_file)\n",
    "\n",
    "cleanAudio, sr = read_audio(clean_file, fs)\n",
    "noisyAudio, sr = read_audio(noisy_file, fs)\n",
    "\n",
    "cleanAudioFeatureExtractor = FeatureExtractor(cleanAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "stft_features = cleanAudioFeatureExtractor.get_stft_spectrogram()\n",
    "stft_features = np.abs(stft_features)\n",
    "print(\"Min:\", np.min(stft_features),\"Max:\",np.max(stft_features))\n",
    "\n",
    "noiseAudioFeatureExtractor = FeatureExtractor(noisyAudio, windowLength=windowLength, overlap=overlap, sample_rate=sr)\n",
    "noise_stft_features = noiseAudioFeatureExtractor.get_stft_spectrogram()\n",
    "\n",
    "# Paper: Besides, spectral phase was not used in the training phase.\n",
    "# At reconstruction, noisy spectral phase was used instead to\n",
    "# perform in- verse STFT and recover human speech.\n",
    "noisyPhase = np.angle(noise_stft_features)\n",
    "noise_stft_features = np.abs(noise_stft_features)\n",
    "\n",
    "mean = np.mean(noise_stft_features)\n",
    "std = np.std(noise_stft_features)\n",
    "noise_stft_features = (noise_stft_features - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == \"cnn\":\n",
    "    predictors = prepare_input_features(noise_stft_features, numSegments, numFeatures)\n",
    "\n",
    "    predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], 1, predictors.shape[2]))\n",
    "    predictors = np.transpose(predictors, (3, 0, 1, 2)).astype(np.float32)\n",
    "    print('predictors.shape:', predictors.shape)\n",
    "\n",
    "    STFTFullyConvolutional = model.predict(predictors)\n",
    "    print(STFTFullyConvolutional.shape)\n",
    "\n",
    "elif model_name == \"lstm\":\n",
    "  predictors = prepare_input_features(noise_stft_features, numSegments, numFeatures)\n",
    "  predictors = np.reshape(predictors, (predictors.shape[0], predictors.shape[1], predictors.shape[2]))\n",
    "  predictors = np.transpose(predictors, (2, 0, 1)).astype(np.float32)\n",
    "  predictors = np.transpose(predictors, (0, 2, 1))\n",
    "  predictors = np.expand_dims(predictors, axis=1)\n",
    "\n",
    "  STFTFullyConvolutional = model.predict(predictors)\n",
    "  STFTFullyConvolutional = STFTFullyConvolutional[..., -1, :]\n",
    "  STFTFullyConvolutional = np.squeeze(STFTFullyConvolutional)\n",
    "  \n",
    "def revert_features_to_audio(features, phase, cleanMean=None, cleanStd=None):\n",
    "    # scale the outpus back to the original range\n",
    "    if cleanMean and cleanStd:\n",
    "        features = cleanStd * features + cleanMean\n",
    "\n",
    "    phase = np.transpose(phase, (1, 0))\n",
    "    features = np.squeeze(features)\n",
    "\n",
    "    # features = librosa.db_to_power(features)\n",
    "    features = features * np.exp(1j * phase)  # that fixes the abs() ope previously done\n",
    "\n",
    "    features = np.transpose(features, (1, 0))\n",
    "    return noiseAudioFeatureExtractor.get_audio_from_stft_spectrogram(features)\n",
    "\n",
    "# A numeric identifier of the sound class -- Types of noise\n",
    "# 0 = air_conditioner\n",
    "# 1 = car_horn\n",
    "# 2 = children_playing\n",
    "# 3 = dog_bark\n",
    "# 4 = drilling\n",
    "# 5 = engine_idling\n",
    "# 6 = gun_shot\n",
    "# 7 = jackhammer\n",
    "# 8 = siren\n",
    "# 9 = street_music\n",
    "\n",
    "# segment, feature, 1, 1\n",
    "denoisedAudioFullyConvolutional = revert_features_to_audio(STFTFullyConvolutional, noisyPhase, mean, std)\n",
    "print(\"Min:\", np.min(denoisedAudioFullyConvolutional),\"Max:\",np.max(denoisedAudioFullyConvolutional))\n",
    "# ipd.Audio(data=denoisedAudioFullyConvolutional, rate=fs) # load a local WAV file\n",
    "\n",
    "print(denoisedAudioFullyConvolutional.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "f, (ax1, ax2, ax3) = plt.subplots(3, 1, sharey=True)\n",
    "\n",
    "ax1.plot(cleanAudio)\n",
    "ax1.set_title(\"Clean Audio\")\n",
    "\n",
    "ax2.plot(noisyAudio)\n",
    "ax2.set_title(\"Noisy Audio\")\n",
    "\n",
    "ax3.plot(denoisedAudioFullyConvolutional)\n",
    "ax3.set_title(\"Denoised Audio\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio(data=denoisedAudioFullyConvolutional, rate=fs) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=cleanAudio, rate=fs) # load a local WAV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(data=noisyAudio, rate=fs) # load a local WAV file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('tf_29_daniel')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "904f93ba5a280e572257a04f19a20f81b654f882c045508efe9071ed46139c46"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
